{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mtrefilek/cs762/blob/main/Feature_Extractor_(ViT).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Itc9z-ILgalu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import ViTModel, ViTFeatureExtractor\n",
        "cwd = os.getcwd().replace('\\\\','/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkOmHREPgalx",
        "outputId": "d76dfff0-765d-40fe-d89a-dc4deab6bea9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at C:/Users/user/Desktop/CS762-Project/pretrained_models/vit-base-patch32-384 were not used when initializing ViTModel: ['classifier.weight', 'classifier.bias']\n",
            "- This IS expected if you are initializing ViTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ViTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ViTModel were not initialized from the model checkpoint at C:/Users/user/Desktop/CS762-Project/pretrained_models/vit-base-patch32-384 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ViTModel(\n",
              "  (embeddings): ViTEmbeddings(\n",
              "    (patch_embeddings): PatchEmbeddings(\n",
              "      (projection): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32))\n",
              "    )\n",
              "    (dropout): Dropout(p=0.0, inplace=False)\n",
              "  )\n",
              "  (encoder): ViTEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): ViTLayer(\n",
              "        (attention): ViTAttention(\n",
              "          (attention): ViTSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (output): ViTSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): ViTIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): ViTOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (1): ViTLayer(\n",
              "        (attention): ViTAttention(\n",
              "          (attention): ViTSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (output): ViTSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): ViTIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): ViTOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (2): ViTLayer(\n",
              "        (attention): ViTAttention(\n",
              "          (attention): ViTSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (output): ViTSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): ViTIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): ViTOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (3): ViTLayer(\n",
              "        (attention): ViTAttention(\n",
              "          (attention): ViTSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (output): ViTSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): ViTIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): ViTOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (4): ViTLayer(\n",
              "        (attention): ViTAttention(\n",
              "          (attention): ViTSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (output): ViTSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): ViTIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): ViTOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (5): ViTLayer(\n",
              "        (attention): ViTAttention(\n",
              "          (attention): ViTSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (output): ViTSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): ViTIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): ViTOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (6): ViTLayer(\n",
              "        (attention): ViTAttention(\n",
              "          (attention): ViTSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (output): ViTSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): ViTIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): ViTOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (7): ViTLayer(\n",
              "        (attention): ViTAttention(\n",
              "          (attention): ViTSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (output): ViTSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): ViTIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): ViTOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (8): ViTLayer(\n",
              "        (attention): ViTAttention(\n",
              "          (attention): ViTSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (output): ViTSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): ViTIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): ViTOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (9): ViTLayer(\n",
              "        (attention): ViTAttention(\n",
              "          (attention): ViTSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (output): ViTSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): ViTIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): ViTOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (10): ViTLayer(\n",
              "        (attention): ViTAttention(\n",
              "          (attention): ViTSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (output): ViTSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): ViTIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): ViTOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (11): ViTLayer(\n",
              "        (attention): ViTAttention(\n",
              "          (attention): ViTSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (output): ViTSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): ViTIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): ViTOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (pooler): ViTPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#%%capture\n",
        "PRETRAINED_MODEL_NAME = 'vit-base-patch32-384' # 'vit-base-patch16-224'\n",
        "d_dim = 768\n",
        "\n",
        "### Model Preparation\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model_path = cwd+'/pretrained_models/'+PRETRAINED_MODEL_NAME\n",
        "\n",
        "# model = ViTModel.from_pretrained('google/'+PRETRAINED_MODEL_NAME)\n",
        "# processor = ViTFeatureExtractor.from_pretrained('google/'+PRETRAINED_MODEL_NAME)\n",
        "# model.save_pretrained(model_path)\n",
        "# processor.save_pretrained(model_path)\n",
        "\n",
        "model = ViTModel.from_pretrained(model_path)\n",
        "processor = ViTFeatureExtractor.from_pretrained(model_path)\n",
        "model.eval()\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSCn82nDAinG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "from copy import deepcopy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQnnWAfsR9yh"
      },
      "outputs": [],
      "source": [
        "DSET_NAME = 'ChestXRay' #('MNIST', 'FMNIST', 'CIFAR10', 'CIFAR100', 'PlantDisease', 'EuroSAT', 'ChestXRay') 'ISIC2018', 'TinyImageNet' are not yet implemented"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLcpNqOEhXlX",
        "scrolled": true,
        "outputId": "56716e94-c3bf-4749-a35d-5a6a31531051"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\anaconda3\\lib\\site-packages\\transformers\\feature_extraction_utils.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_new.cpp:201.)\n",
            "  tensor = as_tensor(value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NORMAL\n",
            "PNEUMONIA\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py:719: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  val = np.asanyarray(val)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NORMAL\n",
            "PNEUMONIA\n"
          ]
        }
      ],
      "source": [
        "### Dataset Preparation\n",
        "from torchvision import datasets\n",
        "from glob import glob, iglob\n",
        "from PIL import Image\n",
        "\n",
        "def batch(iterable, n=1):\n",
        "    l = len(iterable)\n",
        "    for ndx in range(0, l, n):\n",
        "        yield iterable[ndx:min(ndx + n, l)]\n",
        "\n",
        "#import torchvision\n",
        "#transform=torchvision.transforms.Compose([\n",
        "    # you can add other transformations in this list\n",
        "    #torchvision.transforms.ToTensor()\n",
        "#])\n",
        "dset_path = cwd + '/dataset'\n",
        "feature_path = cwd+'/extracted_features/'\n",
        "\n",
        "if DSET_NAME=='MNIST': # MNIST\n",
        "    mnist_train = datasets.MNIST(root=dset_path, train=True, download=True)#, transform=transform)\n",
        "    mnist_test = datasets.MNIST(root=dset_path, train=False, download=True)#, transform=transform)\n",
        "    imgs_tr, imgs_tst, labels_tr, labels_tst = [], [], [], []\n",
        "    for (img, label) in mnist_train:\n",
        "        imgs_tr.append(img.convert(mode='RGB'))\n",
        "        labels_tr.append(label)\n",
        "    for (img, label) in mnist_test:\n",
        "        imgs_tst.append(img.convert(mode='RGB'))\n",
        "        labels_tst.append(label)\n",
        "    classnames = [str(a) for a in range(10)]\n",
        "\n",
        "elif DSET_NAME=='FMNIST': # Fashion-MNIST\n",
        "    fmnist_train = datasets.FashionMNIST(root=dset_path, train=True, download=True)#, transform=transform)\n",
        "    fmnist_test = datasets.FashionMNIST(root=dset_path, train=False, download=True)#, transform=transform)\n",
        "    imgs_tr, imgs_tst, labels_tr, labels_tst = [], [], [], []\n",
        "    for (img, label) in fmnist_train:\n",
        "        imgs_tr.append(img.convert(mode='RGB'))\n",
        "        labels_tr.append(label)\n",
        "    for (img, label) in fmnist_test:\n",
        "        imgs_tst.append(img.convert(mode='RGB'))\n",
        "        labels_tst.append(label)\n",
        "    classnames = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "elif DSET_NAME=='CIFAR10': # CIFAR-10\n",
        "    cifar10_train = datasets.CIFAR10(root=dset_path, train=True, download=True)#, transform=transform)\n",
        "    cifar10_test = datasets.CIFAR10(root=dset_path, train=False, download=True)#, transform=transform)\n",
        "    imgs_tr, imgs_tst, labels_tr, labels_tst = [], [], [], []\n",
        "    for (img, label) in cifar10_train:\n",
        "        imgs_tr.append(img)\n",
        "        labels_tr.append(label)\n",
        "    for (img, label) in cifar10_test:\n",
        "        imgs_tst.append(img)\n",
        "        labels_tst.append(label)\n",
        "    meta = pickle.load( open(dset_path+'/cifar-10-batches-py/batches.meta','rb') )\n",
        "    classnames = meta['label_names']\n",
        "\n",
        "elif DSET_NAME=='CIFAR100': # CIFAR-100\n",
        "    cifar100_train = datasets.CIFAR100(root=dset_path, train=True, download=True)#, transform=transform)\n",
        "    cifar100_test = datasets.CIFAR100(root=dset_path, train=False, download=True)#, transform=transform)\n",
        "    imgs_tr, imgs_tst, labels_tr, labels_tst = [], [], [], []\n",
        "    for (img, label) in cifar100_train:\n",
        "        imgs_tr.append(img)\n",
        "        labels_tr.append(label)\n",
        "    for (img, label) in cifar100_test:\n",
        "        imgs_tst.append(img)\n",
        "        labels_tst.append(label)\n",
        "    meta = pickle.load( open(dset_path+'/cifar-100-python/meta','rb') )\n",
        "    classnames = meta['fine_label_names']\n",
        "\n",
        "elif DSET_NAME in ('PlantDisease','EuroSAT'): # PlantDisease or EuroSAT\n",
        "    list_dirs = glob(dset_path+'/'+DSET_NAME+'/*/')\n",
        "    list_dirs = [l.replace('\\\\','/') for l in list_dirs]\n",
        "    classnames = [d.split('/')[-2] for d in list_dirs]\n",
        "    feature_matrices = []\n",
        "    for i, classname in enumerate(classnames):\n",
        "        imgs = []\n",
        "        for f in iglob(dset_path+'/'+DSET_NAME+'/'+classname+'/*'):\n",
        "            tmp = Image.open(f)\n",
        "            img = tmp.copy().convert(mode='RGB')\n",
        "            imgs.append(img)\n",
        "        print(classname)\n",
        "        feature_matrix = np.zeros((1, d_dim))\n",
        "        for img_batch in batch(imgs, n=32):\n",
        "            inputs = processor(images=img_batch, return_tensors=\"pt\")\n",
        "            img_features = model(**inputs.to(device)).pooler_output.cpu().detach().numpy()\n",
        "            feature_matrix = np.concatenate((feature_matrix, img_features), axis=0)\n",
        "        feature_matrices.append(deepcopy(feature_matrix[1:]))\n",
        "        print(classname)\n",
        "    fname = DSET_NAME+'_'+PRETRAINED_MODEL_NAME+'.npz'\n",
        "    np.savez(feature_path + fname, feature_matrices = feature_matrices, classnames = classnames)\n",
        "\n",
        "elif DSET_NAME=='ChestXRay': # Chest X-Ray\n",
        "    for split in ('train', 'test'):\n",
        "        list_dirs = glob(dset_path+'/'+DSET_NAME+'/'+split+'/*/')\n",
        "        list_dirs = [l.replace('\\\\','/') for l in list_dirs]\n",
        "        classnames = [d.split('/')[-2] for d in list_dirs]\n",
        "        feature_matrices = []\n",
        "        for i, classname in enumerate(classnames):\n",
        "            feature_matrix = np.zeros((1, d_dim))\n",
        "            for f in iglob(dset_path+'/'+DSET_NAME+'/'+split+'/'+classname+'/*'):\n",
        "                tmp = Image.open(f)\n",
        "                img = tmp.copy().convert(mode='RGB')\n",
        "                inputs = processor(images=img, return_tensors=\"pt\")\n",
        "                img_features = model(**inputs.to(device)).pooler_output.cpu().detach().numpy()\n",
        "                feature_matrix = np.concatenate((feature_matrix, img_features), axis=0)\n",
        "            feature_matrices.append(deepcopy(feature_matrix[1:]))\n",
        "            print(classname)\n",
        "        fname = DSET_NAME+'_'+PRETRAINED_MODEL_NAME+'_'+split+'.npz'\n",
        "        np.savez(feature_path + fname, feature_matrices = feature_matrices, classnames = classnames)\n",
        "\n",
        "if DSET_NAME in ('MNIST', 'FMNIST', 'CIFAR10', 'CIFAR100'):\n",
        "    n_tr = len(imgs_tr)\n",
        "    feature_matrix_tr = np.zeros((1,d_dim))\n",
        "    for img_batch in batch(imgs_tr, n=32):\n",
        "        inputs = processor(images=img_batch, return_tensors=\"pt\")\n",
        "        img_features_tr = model(**inputs.to(device)).pooler_output.cpu().detach().numpy()\n",
        "        feature_matrix_tr = np.concatenate((feature_matrix_tr, img_features_tr), axis=0)\n",
        "        print('Extracting Training Features: {0:.2f}% done'.format(100*len(feature_matrix_tr[1:])/n_tr) )\n",
        "    feature_matrix_tr = feature_matrix_tr[1:]\n",
        "\n",
        "    n_cls = np.max(labels_tr)+1\n",
        "    labels_tr = np.array(labels_tr)\n",
        "    feature_matrices_tr = []\n",
        "    for i in range(n_cls):\n",
        "        feature_matrices_tr.append(feature_matrix_tr[labels_tr==i])\n",
        "\n",
        "    n_tst = len(imgs_tst)\n",
        "    feature_matrix_tst = np.zeros((1,d_dim))\n",
        "    for img_batch in batch(imgs_tst, n=32):\n",
        "        inputs = processor(images=img_batch, return_tensors=\"pt\")\n",
        "        img_features_tst = model(**inputs.to(device)).pooler_output.cpu().detach().numpy()\n",
        "        feature_matrix_tst = np.concatenate((feature_matrix_tst, img_features_tst), axis=0)\n",
        "        print('Extracting Test Features: {0:.2f}% done'.format(100*len(feature_matrix_tst[1:])/n_tst) )\n",
        "    feature_matrix_tst = feature_matrix_tst[1:]\n",
        "\n",
        "    n_cls = np.max(labels_tst)+1\n",
        "    labels_tst = np.array(labels_tst)\n",
        "    feature_matrices_tst = []\n",
        "    for i in range(n_cls):\n",
        "        feature_matrices_tst.append(feature_matrix_tst[labels_tst==i])\n",
        "    \n",
        "### Save Features\n",
        "if DSET_NAME in ('MNIST', 'FMNIST', 'CIFAR10', 'CIFAR100'):\n",
        "    fname_tr = DSET_NAME+'_'+PRETRAINED_MODEL_NAME+'_train.npz'\n",
        "    fname_tst = DSET_NAME+'_'+PRETRAINED_MODEL_NAME+'_test.npz'\n",
        "\n",
        "    np.savez(feature_path + fname_tr, feature_matrices = feature_matrices_tr, classnames = classnames)\n",
        "    np.savez(feature_path + fname_tst, feature_matrices = feature_matrices_tst, classnames = classnames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmy7Moqmgal7"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Feature Extractor (ViT).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}